# Inline-comment-generator---Java-

Automatic Code Comment generation plays a good role in the software development life cycle with software maintenance. But in reality, most programmers pay no attention to source code comments; they only pay attention to code, which decreases the program's readability and maintainability. Therefore, a good mechanism for automatic comment generation is needed to solve this problem and improve efficiency. <br>
The developed sequence-to-sequence Transformer consists of a TransformerEncoder and a TransformerDecoder. To make the model aware of the word, a PositionalEmbedding layer is applied. The decoder uses attention to selectively focus on parts of the input sequence. The attention takes a sequence of vectors as input for each example and returns an "attention" vector for each input by dynamically highlighting the relevant features of the input vector. "Accuracy" is used to monitor training progress on the validation data. But BLEU score is more preferred in text-generating tasks.<br>
![ScreenShot_20220814222844](https://user-images.githubusercontent.com/72848727/184548548-b2352b02-2c7a-48ea-9d87-e91cf2ef01fb.png)

The inferencing engine of the comment-generating model is developed in the same google colab environment since it requires high computational resources. A VS code extension and a flask app were also built. Google Colab provides a virtual machine with unlimited computational capacity. But we cannot access the localhost as we do on our local machine. To overcome that issue, “ngrok” python package is used. It enables the locally hosted web server to be hosted on a subdomain of ngrok.com, exposing a local development server to the internet through a public URL.  
