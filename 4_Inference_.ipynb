{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"INFERENCE.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOzdoKaorZU0hDg0KDBM3ka"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Inference Engine\n","\n","<img src=\"https://blogs.gartner.com/paul-debeasi/files/2019/01/Train-versus-Inference.png\">"],"metadata":{"id":"3v6XemsewSXy"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5ioaMWdLqQt","executionInfo":{"status":"ok","timestamp":1650620475155,"user_tz":-330,"elapsed":15,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"2b1f18c8-8357-4c0f-e90b-409758cf3609"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Apr 22 09:41:14 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization"],"metadata":{"id":"xlKpO6GAMhj1","executionInfo":{"status":"ok","timestamp":1650620478020,"user_tz":-330,"elapsed":2869,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super(TransformerEncoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)"],"metadata":{"id":"qqLNwUtgMIlF","executionInfo":{"status":"ok","timestamp":1650620478022,"user_tz":-330,"elapsed":10,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super(PositionalEmbedding, self).__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n"],"metadata":{"id":"9VB36kcSMOUl","executionInfo":{"status":"ok","timestamp":1650620478022,"user_tz":-330,"elapsed":9,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super(TransformerDecoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)\n"],"metadata":{"id":"DiA3HKCMMPDc","executionInfo":{"status":"ok","timestamp":1650620478023,"user_tz":-330,"elapsed":10,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 8\n","vocab_size = 150000 ##??\n","sequence_length = 20 ###????\n","batch_size = 64\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"],"metadata":{"id":"7JFEGU2qMTBl","executionInfo":{"status":"ok","timestamp":1650620482878,"user_tz":-330,"elapsed":4863,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJaVJb9fMY4d","executionInfo":{"status":"ok","timestamp":1650620482880,"user_tz":-330,"elapsed":14,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"b77c2eb8-d001-4f98-dc54-f8a84bd3e110"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," positional_embedding (Position  (None, None, 256)   38405120    ['encoder_inputs[0][0]']         \n"," alEmbedding)                                                                                     \n","                                                                                                  \n"," decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n"," erEncoder)                                                                                       \n","                                                                                                  \n"," model_1 (Functional)           (None, None, 150000  82214640    ['decoder_inputs[0][0]',         \n","                                )                                 'transformer_encoder[0][0]']    \n","                                                                                                  \n","==================================================================================================\n","Total params: 123,775,216\n","Trainable params: 123,775,216\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#Loading Weights\n","\n","#Mounting the gdrive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qow_CEmrNH2m","executionInfo":{"status":"ok","timestamp":1650620508627,"user_tz":-330,"elapsed":25755,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"378b07fb-4f76-4ef5-91d1-01a41c958b4d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["transformer.load_weights(\"/content/drive/MyDrive/Trained Model/For epoch 50-61% accuracy/check/weights-06-0.34.h5\")"],"metadata":{"id":"0knyj_vSNmNA","executionInfo":{"status":"ok","timestamp":1650620515959,"user_tz":-330,"elapsed":6879,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization\n"],"metadata":{"id":"hBiX6e-UTZWw","executionInfo":{"status":"ok","timestamp":1650620515961,"user_tz":-330,"elapsed":15,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Trained Model/For epoch 30, 52% accuarcy/V_cmt.zip\" \"/content/\"\n","!cp \"/content/drive/MyDrive/Trained Model/For epoch 30, 52% accuarcy/V_code.zip\" \"/content/\""],"metadata":{"id":"taUFDxAznXSM","executionInfo":{"status":"ok","timestamp":1650620515961,"user_tz":-330,"elapsed":15,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!unzip /content/V_cmt.zip\n","!unzip /content/V_code.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mnaeh8KaTZuE","executionInfo":{"status":"ok","timestamp":1650620517242,"user_tz":-330,"elapsed":1286,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"2b49c246-f8f9-456b-9921-43047f3a3b4e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/V_cmt.zip\n","   creating: content/vectorizer_cmt/\n","  inflating: content/vectorizer_cmt/keras_metadata.pb  \n","   creating: content/vectorizer_cmt/assets/\n","   creating: content/vectorizer_cmt/variables/\n","  inflating: content/vectorizer_cmt/variables/variables.data-00000-of-00001  \n","  inflating: content/vectorizer_cmt/variables/variables.index  \n","  inflating: content/vectorizer_cmt/saved_model.pb  \n","Archive:  /content/V_code.zip\n","   creating: content/vectorizer_code/\n","  inflating: content/vectorizer_code/keras_metadata.pb  \n","   creating: content/vectorizer_code/assets/\n","   creating: content/vectorizer_code/variables/\n","  inflating: content/vectorizer_code/variables/variables.data-00000-of-00001  \n","  inflating: content/vectorizer_code/variables/variables.index  \n","  inflating: content/vectorizer_code/saved_model.pb  \n"]}]},{"cell_type":"code","source":["loaded_vectorize_layer_model_1 = tf.keras.models.load_model(\"/content/content/vectorizer_cmt\")\n","cmt_vectorization = loaded_vectorize_layer_model_1.layers[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhJ14vbKozxI","executionInfo":{"status":"ok","timestamp":1650620517242,"user_tz":-330,"elapsed":12,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"b872f5bf-ce06-44ea-a184-6247600e7a87"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["loaded_vectorize_layer_model_1 = tf.keras.models.load_model(\"/content/content/vectorizer_code\")\n","code_vectorization = loaded_vectorize_layer_model_1.layers[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed5lzoQAqDPD","executionInfo":{"status":"ok","timestamp":1650620517243,"user_tz":-330,"elapsed":11,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"50b11d03-35ee-4746-f3fe-a1c558ce62f6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["cmt_vocab = cmt_vectorization.get_vocabulary()\n","cmt_index_lookup = dict(zip(range(len(cmt_vocab)), cmt_vocab))\n","max_decoded_sentence_length = 20\n","\n","\n","def decode_sequence(input_sentence):\n","    input_sentence=input_sentence.lower()\n","    tokenized_input_sentence = code_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = cmt_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = cmt_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence"],"metadata":{"id":"gPQJ2hIMR7Dz","executionInfo":{"status":"ok","timestamp":1650620519550,"user_tz":-330,"elapsed":2316,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def final_clean_out(Comment):\n","  claen_cmt=[]\n","  cmt_lst=Comment.split(\" \")\n","  cmt_lst=[i for i in cmt_lst if i !=\"\"]\n","  for i in range(1,len(cmt_lst)):\n","    if cmt_lst[i] != cmt_lst[i-1]:\n","      claen_cmt.append(cmt_lst[i])\n","    if cmt_lst[i]=='end':\n","      break\n","\n","  final_out=\" \".join(claen_cmt[0:-1])\n","  return final_out"],"metadata":{"id":"4k-zdJz5uXFq","executionInfo":{"status":"ok","timestamp":1650622090277,"user_tz":-330,"elapsed":1797,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["#Testing\n","My_code=\"if a>5 then add A=5\"\n","\n","Comment = final_clean_out(decode_sequence(My_code))\n","print(Comment)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8P6UfBrVO0aT","executionInfo":{"status":"ok","timestamp":1650622094228,"user_tz":-330,"elapsed":4,"user":{"displayName":"uvbro business","userId":"06149407597772973103"}},"outputId":"58fb6262-ab32-4685-ec15-26e9f821b143"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["if the current otherwise is by a files event\n"]}]}]}